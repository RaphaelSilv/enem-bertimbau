
=================== Fold 1 / 10 ======================

========== Epoch 1 / 3 ==========
New best model found at fold 1 with MAE: 129.10325151331284

Training Loss: 17740.18, MAE: 128.19
Validation Loss: 17846.55, MAE: 129.10
Epoch 1/3 took: 0:07:42

========== Epoch 2 / 3 ==========
New best model found at fold 1 with MAE: 129.06497753367705

Training Loss: 17645.85, MAE: 127.83
Validation Loss: 17836.52, MAE: 129.06
Epoch 2/3 took: 0:07:43

========== Epoch 3 / 3 ==========
New best model found at fold 1 with MAE: 129.04913442275102

Training Loss: 17628.71, MAE: 127.76
Validation Loss: 17832.36, MAE: 129.05
Epoch 3/3 took: 0:07:43
================================

Fold 1 Average Metrics

fold_1_train_loss_values: [17740.17551016409, 17645.854812264843, 17628.712972277383]
fold_1_val_loss_values: [17846.5495892693, 17836.518497242647, 17832.359633501837]
fold_1_train_mae_values: [128.18539071481763, 127.83437967459892, 127.75534305125973]
fold_1_val_mae_values: [129.10325151331284, 129.06497753367705, 129.04913442275102]
Average Training Loss: 17671.58
Average Training MAE: 127.93
Average Validation Loss: 17838.48
Average Validation MAE: 129.07

Fold 1 took: 0:23:08

=================== Fold 2 / 10 ======================

========== Epoch 1 / 3 ==========
New best model found at fold 2 with MAE: 128.2401621201459

Training Loss: 17657.72, MAE: 127.92
Validation Loss: 17859.59, MAE: 128.24
Epoch 1/3 took: 0:07:43

========== Epoch 2 / 3 ==========
Training Loss: 17638.53, MAE: 127.84
Validation Loss: 17859.59, MAE: 128.24
Epoch 2/3 took: 0:07:43

========== Epoch 3 / 3 ==========
Training Loss: 17659.40, MAE: 127.92
Validation Loss: 17859.59, MAE: 128.24
Epoch 3/3 took: 0:07:43
================================

Fold 2 Average Metrics

fold_2_train_loss_values: [17657.71618284908, 17638.527925114966, 17659.404326269858]
fold_2_val_loss_values: [17859.59485581342, 17859.59485581342, 17859.59485581342]
fold_2_train_mae_values: [127.91787569179982, 127.83953977348813, 127.92110805447683]
fold_2_val_mae_values: [128.2401621201459, 128.2401621201459, 128.2401621201459]
Average Training Loss: 17651.88
Average Training MAE: 127.89
Average Validation Loss: 17859.59
Average Validation MAE: 128.24

Fold 2 took: 0:23:09

=================== Fold 3 / 10 ======================

========== Epoch 1 / 3 ==========
New best model found at fold 3 with MAE: 127.57526240629308

Training Loss: 17701.78, MAE: 128.04
Validation Loss: 17427.39, MAE: 127.58
Epoch 1/3 took: 0:07:43

========== Epoch 2 / 3 ==========
Training Loss: 17696.85, MAE: 128.02
Validation Loss: 17427.39, MAE: 127.58
Epoch 2/3 took: 0:07:43

========== Epoch 3 / 3 ==========
Training Loss: 17697.82, MAE: 128.01
Validation Loss: 17427.39, MAE: 127.58
Epoch 3/3 took: 0:07:43
================================

Fold 3 Average Metrics

fold_3_train_loss_values: [17701.784868833613, 17696.846976902172, 17697.822778401965]
fold_3_val_loss_values: [17427.39194623162, 17427.39194623162, 17427.39194623162]
fold_3_train_mae_values: [128.03636166881958, 128.02130012129462, 128.00846089646967]
fold_3_val_mae_values: [127.57526240629308, 127.57526240629308, 127.57526240629308]
Average Training Loss: 17698.82
Average Training MAE: 128.02
Average Validation Loss: 17427.39
Average Validation MAE: 127.58

Fold 3 took: 0:23:08

=================== Fold 4 / 10 ======================

========== Epoch 1 / 3 ==========
New best model found at fold 4 with MAE: 127.44733989939971

Training Loss: 17694.92, MAE: 128.09
Validation Loss: 17528.15, MAE: 127.45
Epoch 1/3 took: 0:07:42

========== Epoch 2 / 3 ==========
Training Loss: 17702.25, MAE: 128.11
Validation Loss: 17528.15, MAE: 127.45
Epoch 2/3 took: 0:07:43

========== Epoch 3 / 3 ==========
Training Loss: 17694.43, MAE: 128.09
Validation Loss: 17528.15, MAE: 127.45
Epoch 3/3 took: 0:07:43
================================

Fold 4 Average Metrics

fold_4_train_loss_values: [17694.918919183736, 17702.249144283025, 17694.429929191054]
fold_4_val_loss_values: [17528.149442784925, 17528.149442784925, 17528.149442784925]
fold_4_train_mae_values: [128.08672261317838, 128.10964220742318, 128.08596697140698]
fold_4_val_mae_values: [127.44733989939971, 127.44733989939971, 127.44733989939971]
Average Training Loss: 17697.20
Average Training MAE: 128.09
Average Validation Loss: 17528.15
Average Validation MAE: 127.45

Fold 4 took: 0:23:08

=================== Fold 5 / 10 ======================

========== Epoch 1 / 3 ==========
New best model found at fold 5 with MAE: 125.13278691908893

Training Loss: 17758.02, MAE: 128.33
Validation Loss: 16940.43, MAE: 125.13
Epoch 1/3 took: 0:07:43

========== Epoch 2 / 3 ==========
Training Loss: 17752.07, MAE: 128.31
Validation Loss: 16940.43, MAE: 125.13
Epoch 2/3 took: 0:07:43

========== Epoch 3 / 3 ==========
Training Loss: 17772.86, MAE: 128.38
Validation Loss: 16940.43, MAE: 125.13
Epoch 3/3 took: 0:07:44
================================

Fold 5 Average Metrics

fold_5_train_loss_values: [17758.02250339674, 17752.07459761706, 17772.859420725334]
fold_5_val_loss_values: [16940.428969439337, 16940.428969439337, 16940.428969439337]
fold_5_train_mae_values: [128.33487101781327, 128.30986579206078, 128.3804311592842]
fold_5_val_mae_values: [125.13278691908893, 125.13278691908893, 125.13278691908893]
Average Training Loss: 17760.99
Average Training MAE: 128.34
Average Validation Loss: 16940.43
Average Validation MAE: 125.13

Fold 5 took: 0:23:11

=================== Fold 6 / 10 ======================

========== Epoch 1 / 3 ==========
Training Loss: 17686.30, MAE: 128.04
Validation Loss: 17396.68, MAE: 126.71
Epoch 1/3 took: 0:07:43

========== Epoch 2 / 3 ==========
Training Loss: 17682.73, MAE: 128.04
Validation Loss: 17396.68, MAE: 126.71
Epoch 2/3 took: 0:07:42

========== Epoch 3 / 3 ==========
Training Loss: 17676.71, MAE: 128.01
Validation Loss: 17396.68, MAE: 126.71
Epoch 3/3 took: 0:07:43
================================

Fold 6 Average Metrics

fold_6_train_loss_values: [17686.301636966975, 17682.732438205476, 17676.709392636916]
fold_6_val_loss_values: [17396.684728285847, 17396.684728285847, 17396.684728285847]
fold_6_train_mae_values: [128.04449868600904, 128.03669468296013, 128.01106012146607]
fold_6_val_mae_values: [126.71201234705308, 126.71201234705308, 126.71201234705308]
Average Training Loss: 17681.91
Average Training MAE: 128.03
Average Validation Loss: 17396.68
Average Validation MAE: 126.71

Fold 6 took: 0:23:08

=================== Fold 7 / 10 ======================

========== Epoch 1 / 3 ==========
New best model found at fold 7 with MAE: 124.35916631362018

Training Loss: 17743.04, MAE: 128.34
Validation Loss: 16961.93, MAE: 124.36
Epoch 1/3 took: 0:07:43

========== Epoch 2 / 3 ==========
Training Loss: 17727.78, MAE: 128.28
Validation Loss: 16961.93, MAE: 124.36
Epoch 2/3 took: 0:07:43

========== Epoch 3 / 3 ==========
Training Loss: 17724.95, MAE: 128.27
Validation Loss: 16961.93, MAE: 124.36
Epoch 3/3 took: 0:07:42
================================

Fold 7 Average Metrics

fold_7_train_loss_values: [17743.044082488505, 17727.78398372178, 17724.95248157922]
fold_7_val_loss_values: [16961.925680721506, 16961.925680721506, 16961.925680721506]
fold_7_train_mae_values: [128.33729522603014, 128.27701443573304, 128.26882799333552]
fold_7_val_mae_values: [124.35916631362018, 124.35916631362018, 124.35916631362018]
Average Training Loss: 17731.93
Average Training MAE: 128.29
Average Validation Loss: 16961.93
Average Validation MAE: 124.36

Fold 7 took: 0:23:08

=================== Fold 8 / 10 ======================

========== Epoch 1 / 3 ==========
Training Loss: 17761.88, MAE: 128.36
Validation Loss: 16861.17, MAE: 124.51
Epoch 1/3 took: 0:07:43

========== Epoch 2 / 3 ==========
Training Loss: 17771.84, MAE: 128.43
Validation Loss: 16861.17, MAE: 124.51
Epoch 2/3 took: 0:07:43

========== Epoch 3 / 3 ==========
Training Loss: 17752.85, MAE: 128.35
Validation Loss: 16861.17, MAE: 124.51
Epoch 3/3 took: 0:07:42
================================

Fold 8 Average Metrics

fold_8_train_loss_values: [17761.878190975127, 17771.840846441264, 17752.854969037417]
fold_8_val_loss_values: [16861.169383329503, 16861.169383329503, 16861.169383329503]
fold_8_train_mae_values: [128.3640403364813, 128.4256930909428, 128.34561238878945]
fold_8_val_mae_values: [124.50625251321232, 124.50625251321232, 124.50625251321232]
Average Training Loss: 17762.19
Average Training MAE: 128.38
Average Validation Loss: 16861.17
Average Validation MAE: 124.51

Fold 8 took: 0:23:08

=================== Fold 9 / 10 ======================

========== Epoch 1 / 3 ==========
Training Loss: 17647.34, MAE: 127.88
Validation Loss: 17982.88, MAE: 129.36
Epoch 1/3 took: 0:07:43

========== Epoch 2 / 3 ==========
Training Loss: 17631.70, MAE: 127.80
Validation Loss: 17982.88, MAE: 129.36
Epoch 2/3 took: 0:07:43

========== Epoch 3 / 3 ==========
Training Loss: 17640.67, MAE: 127.86
Validation Loss: 17982.88, MAE: 129.36
Epoch 3/3 took: 0:07:42
================================

Fold 9 Average Metrics

fold_9_train_loss_values: [17647.335764396947, 17631.69760856501, 17640.670225621863]
fold_9_val_loss_values: [17982.875093347888, 17982.875093347888, 17982.875093347888]
fold_9_train_mae_values: [127.87563191289487, 127.80106284865568, 127.85803551817419]
fold_9_val_mae_values: [129.359109990737, 129.359109990737, 129.359109990737]
Average Training Loss: 17639.90
Average Training MAE: 127.84
Average Validation Loss: 17982.88
Average Validation MAE: 129.36

Fold 9 took: 0:23:08

=================== Fold 10 / 10 ======================

========== Epoch 1 / 3 ==========
Training Loss: 17622.24, MAE: 127.75
Validation Loss: 18023.28, MAE: 129.49
Epoch 1/3 took: 0:07:42

========== Epoch 2 / 3 ==========
Training Loss: 17605.56, MAE: 127.69
Validation Loss: 18023.28, MAE: 129.49
Epoch 2/3 took: 0:07:42

========== Epoch 3 / 3 ==========
Training Loss: 17614.63, MAE: 127.74
Validation Loss: 18023.28, MAE: 129.49
Epoch 3/3 took: 0:07:42
================================

Fold 10 Average Metrics

fold_10_train_loss_values: [17622.23720670464, 17605.5641036528, 17614.630967156147]
fold_10_val_loss_values: [18023.278521369484, 18023.278521369484, 18023.278521369484]
fold_10_train_mae_values: [127.75432959208919, 127.69311559160417, 127.73540519790905]
fold_10_val_mae_values: [129.48695530610925, 129.48695530610925, 129.48695530610925]
Average Training Loss: 17614.14
Average Training MAE: 127.73
Average Validation Loss: 18023.28
Average Validation MAE: 129.49

Fold 10 took: 0:23:06
overall_train_loss_values[17740.17551016409, 17645.854812264843, 17628.712972277383, 17657.71618284908, 17638.527925114966, 17659.404326269858, 17701.784868833613, 17696.846976902172, 17697.822778401965, 17694.918919183736, 17702.249144283025, 17694.429929191054, 17758.02250339674, 17752.07459761706, 17772.859420725334, 17686.301636966975, 17682.732438205476, 17676.709392636916, 17743.044082488505, 17727.78398372178, 17724.95248157922, 17761.878190975127, 17771.840846441264, 17752.854969037417, 17647.335764396947, 17631.69760856501, 17640.670225621863, 17622.23720670464, 17605.5641036528, 17614.630967156147]
overall_val_loss_values[17846.5495892693, 17836.518497242647, 17832.359633501837, 17859.59485581342, 17859.59485581342, 17859.59485581342, 17427.39194623162, 17427.39194623162, 17427.39194623162, 17528.149442784925, 17528.149442784925, 17528.149442784925, 16940.428969439337, 16940.428969439337, 16940.428969439337, 17396.684728285847, 17396.684728285847, 17396.684728285847, 16961.925680721506, 16961.925680721506, 16961.925680721506, 16861.169383329503, 16861.169383329503, 16861.169383329503, 17982.875093347888, 17982.875093347888, 17982.875093347888, 18023.278521369484, 18023.278521369484, 18023.278521369484]
overall_train_mae_values[128.18539071481763, 127.83437967459892, 127.75534305125973, 127.91787569179982, 127.83953977348813, 127.92110805447683, 128.03636166881958, 128.02130012129462, 128.00846089646967, 128.08672261317838, 128.10964220742318, 128.08596697140698, 128.33487101781327, 128.30986579206078, 128.3804311592842, 128.04449868600904, 128.03669468296013, 128.01106012146607, 128.33729522603014, 128.27701443573304, 128.26882799333552, 128.3640403364813, 128.4256930909428, 128.34561238878945, 127.87563191289487, 127.80106284865568, 127.85803551817419, 127.75432959208919, 127.69311559160417, 127.73540519790905]
overall_val_mae_values[129.10325151331284, 129.06497753367705, 129.04913442275102, 128.2401621201459, 128.2401621201459, 128.2401621201459, 127.57526240629308, 127.57526240629308, 127.57526240629308, 127.44733989939971, 127.44733989939971, 127.44733989939971, 125.13278691908893, 125.13278691908893, 125.13278691908893, 126.71201234705308, 126.71201234705308, 126.71201234705308, 124.35916631362018, 124.35916631362018, 124.35916631362018, 124.50625251321232, 124.50625251321232, 124.50625251321232, 129.359109990737, 129.359109990737, 129.359109990737, 129.48695530610925, 129.48695530610925, 129.48695530610925]

================================ Training complete! ================================
Overall summary:
Average Training Loss: 17691.05
Average Validation Loss: 17482.00
Average Training MAE: 128.06
Average Validation MAE: 127.19
All folds took: 3:51:22
Best model was from fold with MAE: 124.36
